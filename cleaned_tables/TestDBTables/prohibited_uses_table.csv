prohibited_uses_id,prohibited_uses
1,"""... should not be used for any of the unacceptable language model use cases, e.g., generation of toxic speech"" [[Datasheet]](https://arxiv.org/pdf/2204.02311.pdf#appendix.D).
"
2,"""Any deployed use case of the model - whether commercial or not - is currently out of scope. Non-deployed use cases such as image search in a constrained environment, are also not recommended unless there is thorough in-domain testing of the model with a specific, fixed class taxonomy. This is because our safety assessment demonstrated a high need for task specific testing especially given the variability of CLIP’s performance with different class taxonomies. This makes untested and unconstrained deployment of the model in any use case currently potentially harmful.
Certain use cases which would fall under the domain of surveillance and facial recognition are always out-of-scope regardless of performance of the model. This is because the use of artificial intelligence for tasks such as these can be premature currently given the lack of testing norms and checks to ensure its fair use.
Since the model has not been purposefully trained in or evaluated on any languages other than English, its use should be limited to English language use cases"" [[Model Card]](https://github.com/openai/CLIP/blob/main/model-card.mdlicen).
"
3,"- Authors note the following prohibited uses: ""You must not use the content other than for the Permitted Purpose in strict conformity with these terms and any other reasonable instructions of the University. You must not, except as may be strictly necessary for carrying out the Permitted Purpose, provide or otherwise make available content to any third party or allow use of it or them by or on behalf of any third party, in whole or in part, whether by way of sale, resale, loan, transfer, hire or any other form of exploitation; or attempt to identify any living or deceased individual from the content."" [[Terms of Access]](https://github.com/m-bain/webvid/blob/main/TERMS.md)
- Authors also note the following limitations of the dataset: ""We note that data sourced from the web may be prone to biases and may contain graphic content. Please be careful of unintended societal, gender, racial and other biases when training or deploying models trained on this data."" [[Disclaimer]](https://github.com/m-bain/webvid#disclaimer-%EF%B8%8F)
"
4,"AI/ML training, attempting to create abusive, illegal, or confidential content."
5,"Access to GPT-3 is governed by GitHub Acceptable Use Policies and Terms of Service, both of which list a set of prohibited uses [[Use Policies]] (https://docs.github.com/en/site-policy/acceptable-use-policies/github-acceptable-use-policies) [[Terms of Service]] (https://docs.github.com/en/site-policy/github-terms/github-terms-of-service).
"
6,"Access to GPT-3 is governed by Open AI API Usage Guidelines and API Terms of Use, prohibiting the use of the API in a way that causes societal harm. [[Usage Guidelines]] (https://beta.openai.com/docs/usage-guidelines/content-policy) [[Terms of Use]](https://openai.com/api/policies/terms/). The list of disallowed applications can be found in the usage guidelines [[Disallowed Applications]] (https://beta.openai.com/docs/usage-guidelines/disallowed-applications).
"
7,"Access to InstructGPT is governed by Open AI API Usage Guidelines and API Terms of Use, prohibiting the use of the API in a way that causes societal harm. [[Usage Guidelines]] (https://beta.openai.com/docs/usage-guidelines/content-policy) [[Terms of Use]](https://openai.com/api/policies/terms/). The list of disallowed applications can be found in the usage guidelines [[Disallowed Applications]] (https://beta.openai.com/docs/usage-guidelines/disallowed-applications).
"
8,Any purposes other than research.
9,Any tasks which may considered irresponsible or harmful.
10,"Authors note the following limitations of the dataset:
  The masks are generated by a segmentation model, so there may be errors
or inconsistencies in the masks.
  While no two images are the same, there are instances of images of the same
subject taken close together in time.
  The dataset contains scenes of protests, or other gatherings that may suggest
religious beliefs, political opinions or union memberships that may be offensive.
"
11,"Authors note the following limitations of the model: ""Cerebras-GPT models are trained on the Pile, with English language only, and are not suitable for machine translation tasks. Cerebras-GPT models have not been tuned for human-facing dialog applications like chatbots and will not respond to prompts in a similar way to models that have received instruction tuning or reinforcement learning from human feedback (RLHF) like Flan-T5 or ChatGPT."" [[Uses and Limitations]](https://github.com/Cerebras/modelzoo/tree/main/modelzoo/transformers/pytorch/gpt3/configs/Cerebras_GPT#out-of-scope-use).
"
12,"Authors note the following limitations of the model: ""The Dolly model family is under active development, and so any list of shortcomings is unlikely to be exhaustive, but we include known limitations and misfires here as a means to document and share our preliminary findings with the community. In particular, dolly-6b struggles with syntactically complex prompts, mathematical operations, factual errors, dates and times, open-ended question answering, hallucination, enumerating lists of specific length, and stylistic mimicry."" [[Limitations]](https://github.com/databrickslabs/dolly#limitations).
"
13,"Authors note the following limitations: ""Kakao Brain tried to construct a ""Safe"" dataset when building the COYO dataset. However, despite these efforts, this large-scale dataset was not hand-picked by humans to avoid the risk due to its very large size (over 700M). Keep in mind that the unscreened nature of the dataset means that the collected images can lead to strongly discomforting and disturbing content for humans. The COYO dataset may contain some inappropriate data, and any problems resulting from such data are the full responsibility of the user who used it.""
"
14,Claude 2 should not be used on their own in high stakes situations where an incorrect answer would cause harm.
15,"DBRX models are not intended to be used out-of-the-box in non-English languages, and do not support native code execution, function calling or any use that violates applicable laws or regulations or is otherwise prohibited by the Databricks Open Model License and Databricks Open Model Acceptable Use Policy."
16,"For out-of-scope use cases see terms of use in [[LICENSE]](https://github.com/facebookresearch/segment-anything/blob/main/LICENSE). Authors also discuss the following limitations of the model: ""While SAM performs well in general, it is not perfect. It can miss fine structures, hallucinates small disconnected components at times, and does not produce boundaries as crisply as more computationally intensive methods that “zoom-in”, e.g. [18]. In general, we expect dedicated interactive segmentation methods to outperform SAM when many points are provided, e.g. [67]. Unlike these methods, SAM is designed for generality and breadth of use rather than high IoU interactive segmentation. Moreover, SAM can process prompts in real-time, but nevertheless SAM's overall performance is not real-time when using a heavy image encoder. Our foray into the text-to-mask task is exploratory and not entirely robust, although we believe it can be improved with more effort. While SAM can perform many tasks, it is unclear how to design simple prompts that implement semantic and panoptic segmentation. Finally, there are domain-specific tools, such as [7], that we expect to outperform SAM in their respective domains.""
"
17,"Generating or endorsing hate speech, disseminating false information, engaging in illegal activities, managing sensitive data, attempting language generalization beyond Arabic and English, and making critical decisions with high stakes."
18,"Illegal activities, such as hate speech, gambling, child pornography or violating intellectual property rights; Harassment, victimization, intimidation, fraud or spam; Creation or dissemination of misinformation, promotion of self-harm, glorification of violent events or incitement of violence."
19,"Illegal or abusive activity, security violations, network abuse
"
20,It cannot be used for commercial purposes.
21,It should not be used for tasks that infringe on copyright laws.
22,"No explicit prohibited uses stated, though it is noted that users should undertake thorough safety testing."
23,"No uses are explicitly prohibited by the authors. They note the following limitations of the dataset: ""We note that the distribution of identities and activities in the HowTo100M dataset may not be representative of the global human population and the diversity in society. Please be careful of unintended societal, gender, racial and other biases when training or deploying models trained on this data.""
"
24,No uses are explicitly prohibited by the license. Users are warned from using LAION-2B-en for non-research purposes.
25,No uses are explicitly prohibited by the license. Users are warned from using LAION-400M for any real-world production or application.
26,No uses are explicitly prohibited by the license. Users are warned from using LAION-5B for non-research purposes.
27,Not suitable for creating realistic photos or for users who expect high-quality results from short or simple prompts.
28,"OpenAI API Terms of Use prohibits the use of the API in a way violating the applicable law, including: (i) ""Illegal activities, such as child pornography, gambling, cybercrime, piracy, violating copyright, trademark or other intellectual property laws""; (ii) ""Accessing or authorizing anyone to access the APIs from an embargoed country, region, or territory as prohibited by the U.S. government""; (iii) ""Threatening, stalking, defaming, defrauding, degrading, victimizing or intimidating anyone for any reason"". The usage requirements are detailed in the Terms of Use [[Section 3]](https://openai.com/api/policies/terms/).
"
29,"Per the [[HuggingFace repository]](https://huggingface.co/facebook/flava-full), ""Any deployed use case of the model - whether commercial or not"" - is currently out of scope.
"
30,Production use without adequate assessment of risks and mitigation; any use cases which may be considered irresponsible or harmful.
31,Prohibited from deploying in production environments for natural language generation or any professional health and medical purposes.
32,"Prohibited use cases aren't specifically spelled out for Google search, but several illegal and discouraged use cases are shared in the Respect Others section of the [[Term of Service]](https://policies.google.com/terms).
"
33,"Prohibited uses are listed in the Terms of Service [[Terms of Service]](https://www.askviable.com/terms-of-service). The terms don't include statements specific to the use of the content generated by the system or GPT-3.
"
34,Prohibited uses are specified in the Gemma Prohibited Use Policy here https://ai.google.dev/gemma/prohibited_use_policy
35,"Prohibited uses include, but are not limited to, political campaigning or lobbying, surveillance, social scoring, criminal justice decisions, law enforcement, and decisions related to financing, employment, and housing."
36,"SambaLingo should not be used for mission-critical applications, applications involving the safety of others, and highly critical decisions."
37,See BigCode Open RAIL-M license and FAQ
38,See https://huggingface.co/datasets/bigcode/the-stack
39,The data must not be utilized for malicious or harmful purposes towards humanity.
40,"The model ""should not be used for downstream applications without further analysis on factors in the proposed downstream application [[Model Card]](https://arxiv.org/pdf/2204.02311.pdf#appendix.E)""
"
41,"The model card lists the following as out of scope uses of the model: ""Not intended for commercial or production use. Military uses are strictly prohibited."" [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
"
42,"The model card lists the following as out of scope uses of the model: ""Uses of the model for visually conditioned language generation in harmful or deceitful settings. Broadly speaking, the model should not be used for downstream applications without further safety and fairness mitigations specific to each application."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
"
43,"The model card lists the following as out of scope uses of the model: ""for language generation in harmful or deceitful settings. More generally, the model should not be used for downstream applications without further safety and fairness mitigations"" [[Model Card]](https://arxiv.org/pdf/2112.11446.pdf#appendix.B).
"
44,"The model card lists the following as out of scope uses of the model: ""for language generation in harmful or deceitful settings. More generally, the model should not be used for downstream applications without further safety and fairness mitigations"" [[Model Card]](https://arxiv.org/pdf/2203.15556.pdf#appendix.I).
"
45,"The model should not be used for generating factual or true representations of people or events, or in any way that violates Stability AIs Acceptable Use Policy."
46,"The model should not be used for high-risk scenarios without adequate evaluation and mitigation techniques for accuracy, safety, and fairness."
47,"The model should not be used in a way that could lead to inaccurate, misleading or potentially harmful generation. Users should comply with local laws and regulations when deploying the model."
48,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes."
49,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate music pieces that create hostile or alienating environments for people. This includes generating music that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes."
50,"The model was not trained to be factual or true representations of people or events, and therefore using the model to generate such content is out-of-scope for the abilities of this model."
51,"The model was not trained to be factual or true representations of people or events, and therefore using the model to generate such content is out-of-scope for the abilities of this model. The model should not be used in any way that violates Stability AI's Acceptable Use Policy."
52,"The prohibited uses for Infiniset weren't specifically listed, but the Google AI principles inspired safety objectives in [[Appendix A.1]](https://arxiv.org/pdf/2201.08239.pdf#subsection.A.1) advises avoiding harm, unjust impact and misinformation, among others.
"
53,"The prohibited uses of LaMDA weren't specifically listed, but the Google AI principles inspired safety objectives in [[Appendix A.1]](https://arxiv.org/pdf/2201.08239.pdf#subsection.A.1) advises avoiding harm, unjust impact and misinformation, among others.
"
54,"The usage of the API is bound by the Cohere usage guidelines. Disallowed use cases include violence and threats, antisocial and antidemocratic uses, deceit, attacks on security or privacy, unsafe unsupervised uses, decision-making, high-Risk generations among others [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
"
55,"The usage of the model is bound by the Cohere usage guidelines [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines). A non-comprehensive list of specific application violating these guidelines are: astroturfing, generation of misinformation and other harmful content, and ""generation of text about people, places, or events without a human-in-the-loop"" [[Model Card]](https://docs.cohere.ai/generation-card).
"
56,"The usage of the model is bound by the Cohere usage guidelines [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines). A non-comprehensive list of specific application violating these guidelines are: extraction of identity and demographic information, building purposefully opaque text classification systems, and ""building downstream classifiers that serve as automated decision-making systems that have real-world consequences on people, where those decisions are made without a human-in-the-loop"" [[Model Card]](https://docs.cohere.ai/representation-card).
"
57,"This dataset only contains rankings for prompts, not prompt/response pairs so it is not suitable for direct use for supervised fine-tuning of language models."
58,Unfit for real-world deployment in the safety-critical medical domain.
59,Uploading copyrighted material for transformation.
60,Use in any manner that violates applicable laws or regulations (including trade compliance laws). Use in languages other than English. Use in any other way that is prohibited by the Acceptable Use Policy and Licensing Agreement for Code Llama and its variants.
61,Use in any manner that violates applicable laws or regulations (including trade compliance laws). Use in languages other than English. Use in any other way that is prohibited by the Acceptable Use Policy and Licensing Agreement for Llama 2.
62,"Use of the model is governed by the OpenAI Content Policy, which prohibits posting of G rated content. Users are not allowed to utilize the model in commercial products in the preview version [[Content Policy]] (https://github.com/openai/dalle-2-preview/blob/main/system-card.md#policies-and-enforcement)."
63,"Use of the model is governed by the OpenAI Content Policy, which prohibits posting of G rated content. Users are not allowed to utilize the model in commercial products in the preview version."
64,"Users are encouraged to use the large language model responsibly and ethically. By using this model, you agree not to use it for purposes that promote hate speech, discrimination, harassment, or any form of illegal or harmful activities."
65,"Using the model in high-stakes settings is out of scope for this model (e.g. biomedical/political/legal/finance domains, evaluating or scoring individuals). The model is not designed for critical decisions nor uses with any material consequences on an individual's livelihood or wellbeing. The model outputs content that appears factual but may not be correct. Misuse. Intentionally using the model for harm, violating human rights, or other kinds of malicious activities, is a misuse of this model (e.g. spam generation, disinformation, disparagement, deception, surveillance)."
66,Using the model to generate representations of real-world people or events.
67,becoming part of a general-purpose service or product or use within specific downstream applications without prior assessment
68,commercial use
69,irresponsible or harmful use or production use without adequate assessment of risks and mitigation.
70,unknown
