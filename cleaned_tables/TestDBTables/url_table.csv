url_id,url
1,goose.ai
2,http://eaidata.bmk.sh/data/GPT_NeoX_20B.pdf
3,https://about.ideogram.ai/1.0
4,https://academic.oup.com/bib/article/23/6/bbac409/6713511?guestAccessKey=a66d9b5d-4f83-4017-bb52-405815c907b9&login=true
5,https://aclanthology.org/P18-1238/
6,https://ai.facebook.com/datasets/segment-anything/
7,https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/
8,https://ai.meta.com/research/publications/emu-enhancing-image-generation-models-using-photogenic-needles-in-a-haystack/
9,https://ai.meta.com/resources/models-and-libraries/llama/
10,https://allenai.org/olmo/olmo-paper.pdf
11,https://app.twelvelabs.io/blog/introducing-pegasus-1
12,https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/
13,https://argilla.io/blog/notus7b/
14,https://arxiv.org/abs/1910.10683
15,https://arxiv.org/abs/2005.00341
16,https://arxiv.org/abs/2102.12092
17,https://arxiv.org/abs/2104.04473
18,https://arxiv.org/abs/2104.11178
19,https://arxiv.org/abs/2105.13290
20,https://arxiv.org/abs/2109.01652
21,https://arxiv.org/abs/2109.04650
22,https://arxiv.org/abs/2111.02358
23,https://arxiv.org/abs/2111.11432
24,https://arxiv.org/abs/2112.04426
25,https://arxiv.org/abs/2112.04482
26,https://arxiv.org/abs/2112.06905
27,https://arxiv.org/abs/2112.12731
28,https://arxiv.org/abs/2112.15283
29,https://arxiv.org/abs/2201.02639
30,https://arxiv.org/abs/2201.11990
31,https://arxiv.org/abs/2201.12086
32,https://arxiv.org/abs/2202.13169
33,https://arxiv.org/abs/2203.07814
34,https://arxiv.org/abs/2203.13474
35,https://arxiv.org/abs/2204.01691
36,https://arxiv.org/abs/2204.05999
37,https://arxiv.org/abs/2204.06125
38,https://arxiv.org/abs/2204.07705
39,https://arxiv.org/abs/2204.14217
40,https://arxiv.org/abs/2205.01068
41,https://arxiv.org/abs/2205.05131
42,https://arxiv.org/abs/2205.15868
43,https://arxiv.org/abs/2206.08853
44,https://arxiv.org/abs/2206.11795
45,https://arxiv.org/abs/2206.14858
46,https://arxiv.org/abs/2208.12415
47,https://arxiv.org/abs/2209.03143
48,https://arxiv.org/abs/2209.06794
49,https://arxiv.org/abs/2209.14375
50,https://arxiv.org/abs/2209.14958
51,https://arxiv.org/abs/2210.11399
52,https://arxiv.org/abs/2210.11416
53,https://arxiv.org/abs/2210.15257
54,https://arxiv.org/abs/2211.01786
55,https://arxiv.org/abs/2211.05100
56,https://arxiv.org/abs/2212.12017
57,https://arxiv.org/abs/2212.13138
58,https://arxiv.org/abs/2301.13688
59,https://arxiv.org/abs/2302.05442
60,https://arxiv.org/abs/2302.13971
61,https://arxiv.org/abs/2302.14115
62,https://arxiv.org/abs/2303.01037
63,https://arxiv.org/abs/2303.03378
64,https://arxiv.org/abs/2303.08774
65,https://arxiv.org/abs/2303.17564
66,https://arxiv.org/abs/2309.04662
67,https://arxiv.org/abs/2309.16609
68,https://arxiv.org/abs/2402.16107
69,https://arxiv.org/abs/2404.02078
70,https://arxiv.org/abs/2404.14219
71,https://arxiv.org/pdf/1906.03327.pdf
72,https://arxiv.org/pdf/2005.14165.pdf
73,https://arxiv.org/pdf/2101.00027.pdf
74,https://arxiv.org/pdf/2102.08981.pdf
75,https://arxiv.org/pdf/2102.12092.pdf
76,https://arxiv.org/pdf/2103.00020.pdf
77,https://arxiv.org/pdf/2107.03374.pdf
78,https://arxiv.org/pdf/2110.08207.pdf
79,https://arxiv.org/pdf/2112.05253.pdf
80,https://arxiv.org/pdf/2112.11446.pdf
81,https://arxiv.org/pdf/2201.08239.pdf
82,https://arxiv.org/pdf/2203.02155.pdf
83,https://arxiv.org/pdf/2203.15556.pdf
84,https://arxiv.org/pdf/2204.02311.pdf
85,https://arxiv.org/pdf/2204.05862.pdf
86,https://arxiv.org/pdf/2204.08583.pdf
87,https://arxiv.org/pdf/2204.14198.pdf
88,https://arxiv.org/pdf/2208.10442.pdf
89,https://arxiv.org/pdf/2208.11663.pdf
90,https://arxiv.org/pdf/2209.14792.pdf
91,https://arxiv.org/pdf/2210.08402.pdf
92,https://arxiv.org/pdf/2211.01786.pdf
93,https://arxiv.org/pdf/2211.12737.pdf
94,https://arxiv.org/pdf/2211.15533.pdf
95,https://arxiv.org/pdf/2212.03191.pdf
96,https://arxiv.org/pdf/2212.10465.pdf
97,https://arxiv.org/pdf/2212.10551.pdf
98,https://arxiv.org/pdf/2301.03988.pdf
99,https://arxiv.org/pdf/2301.11325.pdf
100,https://arxiv.org/pdf/2301.12597.pdf
101,https://arxiv.org/pdf/2302.09778.pdf
102,https://arxiv.org/pdf/2302.14045.pdf
103,https://arxiv.org/pdf/2303.04671.pdf
104,https://arxiv.org/pdf/2303.17564.pdf#section.2
105,https://arxiv.org/pdf/2304.01373.pdf
106,https://arxiv.org/pdf/2304.02643.pdf
107,https://arxiv.org/pdf/2304.06939.pdf
108,https://arxiv.org/pdf/2304.12244v1.pdf
109,https://arxiv.org/pdf/2305.03726v1.pdf
110,https://arxiv.org/pdf/2305.06161.pdf
111,https://arxiv.org/pdf/2305.14201.pdf
112,https://arxiv.org/pdf/2305.14314v1.pdf
113,https://arxiv.org/pdf/2305.15334v1.pdf
114,https://arxiv.org/pdf/2305.17100.pdf
115,https://arxiv.org/pdf/2305.18098v1.pdf
116,https://arxiv.org/pdf/2306.01116.pdf
117,https://arxiv.org/pdf/2306.07012.pdf
118,https://arxiv.org/pdf/2306.07944.pdf
119,https://arxiv.org/pdf/2306.08161.pdf
120,https://arxiv.org/pdf/2306.08568.pdf
121,https://arxiv.org/pdf/2307.14334.pdf
122,https://arxiv.org/pdf/2307.15818.pdf
123,https://arxiv.org/pdf/2307.16372.pdf
124,https://arxiv.org/pdf/2308.07317.pdf
125,https://arxiv.org/pdf/2309.00071.pdf
126,https://arxiv.org/pdf/2309.05463.pdf
127,https://arxiv.org/pdf/2309.05653.pdf
128,https://arxiv.org/pdf/2309.09400
129,https://arxiv.org/pdf/2309.10305.pdf
130,https://arxiv.org/pdf/2309.10706.pdf
131,https://arxiv.org/pdf/2309.17080.pdf
132,https://arxiv.org/pdf/2310.03731.pdf
133,https://arxiv.org/pdf/2310.04292.pdf
134,https://arxiv.org/pdf/2310.06786.pdf
135,https://arxiv.org/pdf/2310.06830.pdf
136,https://arxiv.org/pdf/2310.07160.pdf
137,https://arxiv.org/pdf/2310.07704.pdf
138,https://arxiv.org/pdf/2310.10631.pdf
139,https://arxiv.org/pdf/2310.10967.pdf
140,https://arxiv.org/pdf/2310.16825.pdf
141,https://arxiv.org/pdf/2310.17631.pdf
142,https://arxiv.org/pdf/2310.19341.pdf
143,https://arxiv.org/pdf/2311.03079.pdf
144,https://arxiv.org/pdf/2311.05640.pdf
145,https://arxiv.org/pdf/2311.05997.pdf
146,https://arxiv.org/pdf/2311.06242.pdf
147,https://arxiv.org/pdf/2311.09257.pdf
148,https://arxiv.org/pdf/2311.10702.pdf
149,https://arxiv.org/pdf/2311.11045.pdf
150,https://arxiv.org/pdf/2311.16079.pdf
151,https://arxiv.org/pdf/2311.16867.pdf
152,https://arxiv.org/pdf/2312.08688.pdf
153,https://arxiv.org/pdf/2312.14862.pdf
154,https://arxiv.org/pdf/2401.13560v2.pdf
155,https://arxiv.org/pdf/2401.14688.pdf
156,https://arxiv.org/pdf/2401.16818.pdf
157,https://arxiv.org/pdf/2402.02592.pdf
158,https://arxiv.org/pdf/2402.03216.pdf
159,https://arxiv.org/pdf/2402.03885.pdf
160,https://arxiv.org/pdf/2402.04252.pdf
161,https://arxiv.org/pdf/2402.06619.pdf
162,https://arxiv.org/pdf/2402.07827.pdf
163,https://arxiv.org/pdf/2402.07865.pdf
164,https://arxiv.org/pdf/2402.10373.pdf
165,https://arxiv.org/pdf/2402.13929.pdf
166,https://arxiv.org/pdf/2402.16819.pdf
167,https://arxiv.org/pdf/2403.09611.pdf
168,https://arxiv.org/pdf/2404.00399
169,https://arxiv.org/pdf/2404.01294
170,https://arxiv.org/pdf/2404.01954
171,https://arxiv.org/pdf/2404.18416
172,https://arxiv.org/pdf/2405.09818
173,https://arxiv.org/pdf/2405.13063
174,https://arxiv.org/pdf/2405.13386
175,https://arxiv.org/pdf/2405.15032
176,https://aws.amazon.com/bedrock/
177,https://azure.microsoft.com/en-us/blog/announcing-a-renaissance-in-computer-vision-ai-with-microsofts-florence-foundation-model/?utm_content=buffer16fa0&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer
178,https://bair.berkeley.edu/blog/2023/04/03/koala/
179,https://beta.character.ai/
180,https://blog.allenai.org/dolma-3-trillion-tokens-open-llm-corpus-9a0ff4b8da64
181,https://blog.duolingo.com/duolingo-max/
182,https://blog.eleuther.ai/pile-t5/
183,https://blog.google/products/search/introducing-mum/
184,https://blog.google/products/search/search-language-understanding-bert/
185,https://blog.google/technology/ai/bard-google-ai-search-updates/
186,https://blog.google/technology/ai/google-palm-2-ai-large-language-model/
187,https://blog.google/technology/ai/join-us-in-the-ai-test-kitchen/
188,https://blog.google/technology/developers/gemma-open-models/
189,https://blog.research.google/2024/02/a-decoder-only-foundation-model-for.html
190,https://blog.salesforceairesearch.com/moirai/
191,https://blogs.microsoft.com/blog/2023/02/07/reinventing-search-with-a-new-ai-powered-microsoft-bing-and-edge-your-copilot-for-the-web/
192,https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/
193,https://blogs.microsoft.com/blog/2023/03/28/introducing-microsoft-security-copilot-empowering-defenders-at-the-speed-of-ai/
194,https://cagliostrolab.net/posts/animagine-xl-v31-release
195,https://cartesia.ai/blog/sonic
196,https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf
197,https://cdn.openai.com/papers/whisper.pdf
198,https://chatcamel.vercel.app/
199,https://chatglm.cn/blog
200,https://clipdrop.co/real-estate/sky-replacer
201,https://cloud.google.com/vertex-ai/docs/generative-ai/medlm/overview
202,https://cohere.ai/
203,https://cohere.com/blog/rerank-3
204,https://console.anthropic.com/docs/api
205,https://continue.dev
206,https://copilot.github.com/
207,https://cosmicman-cvpr2024.github.io/
208,https://cresta.com/blog/introducing-ocean-1-worlds-first-contact-center-foundation-model/
209,https://crfm.stanford.edu/2022/12/15/pubmedgpt.html
210,https://crfm.stanford.edu/2023/03/13/alpaca.html
211,https://dais.com/underwritegpt/
212,https://deci.ai/blog/introducing-decilm-7b-the-fastest-and-most-accurate-7b-large-language-model-to-date
213,https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/
214,https://deepmind.google/technologies/gemini/#introduction
215,https://deepmind.google/technologies/gemini/flash/
216,https://deepmind.google/technologies/imagen-3/
217,https://deepmind.google/technologies/veo/
218,https://developers.googleblog.com/2023/03/announcing-palm-api-and-makersuite.html
219,https://docs.ai21.com/docs/jurassic-1-instruct-beta
220,https://docs.ai21.com/docs/jurassic-2-models
221,https://docs.ai21.com/docs/paraphrase-api
222,https://docs.ai21.com/docs/summarize-api
223,https://docs.cohere.ai/reference/classify
224,https://docs.cohere.ai/reference/embed
225,https://docs.cohere.ai/reference/generate
226,https://docs.cohere.ai/reference/summarize
227,https://docs.cohere.com/docs/command-beta
228,https://ecosystem.hubspot.com/marketplace/apps/sales/sales-enablement/the-obo-group-chatgpt-1398072
229,https://emu-edit.metademolab.com/
230,https://emu-video.metademolab.com/
231,https://en.konantech.com/en/llm/konanllm
232,https://erichartford.com/dolphin
233,https://faradaylab.fr/
234,https://felixkreuk.github.io/audiogen/paper.pdf
235,https://firefly.adobe.com/
236,https://fortune.com/2023/03/07/cfo-chatbot-chatgpt-ai-brex-finance-software-startup-budgets-policies/
237,https://galactica.org/static/paper.pdf
238,https://github.com/01-ai/Yi
239,https://github.com/DAMO-NLP-SG/SeaLLMs
240,https://github.com/EleutherAI/gpt-neo
241,https://github.com/GeneZC/MiniMA
242,https://github.com/GreenBitAI/low_bit_llama
243,https://github.com/InternLM/InternLM
244,https://github.com/NASA-IMPACT/hls-foundation-os
245,https://github.com/OpenBMB/CPM-Bee
246,https://github.com/OpenBMB/MiniCPM/
247,https://github.com/OpenBMB/UltraFeedback
248,https://github.com/OpenGVLab/InternVideo2
249,https://github.com/OrionStarAI/Orion
250,https://github.com/Stability-AI/StableLM
251,https://github.com/THUDM/CodeGeeX
252,https://github.com/XueFuzhao/OpenMoE
253,https://github.com/amazon-science/chronos-forecasting
254,https://github.com/bytedance/SALMONN
255,https://github.com/deepseek-ai/DeepSeek-Coder
256,https://github.com/deepseek-ai/DeepSeek-LLM
257,https://github.com/kakaobrain/coyo-dataset
258,https://github.com/ncsoft/ncresearch
259,https://github.com/openlm-research/open_llama
260,https://github.com/suno-ai/bark
261,https://github.com/thunlp/UltraChat
262,https://github.com/thunlp/UltraChat#UltraLM
263,https://github.com/xverse-ai/XVERSE-65B
264,https://github.com/yifanzhang-pro/AutoMathText
265,https://global.rakuten.com/corp/news/press/2024/0321_01.html
266,https://google-research.github.io/noise2music/noise2music.pdf
267,https://gpt3demo.com/apps/palmyra
268,https://grok.x.ai/
269,https://help.nextdoor.com/s/article/Introducing-Assistant
270,https://huggingface.co/CausalLM/14B
271,https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha
272,https://huggingface.co/KT-AI/midm-bitext-S-7B-inst-v1
273,https://huggingface.co/MayaPH/GodziLLa2-70B
274,https://huggingface.co/NousResearch/Genstruct-7B
275,https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B
276,https://huggingface.co/NousResearch/Nous-Capybara-34B
277,https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO
278,https://huggingface.co/Open-Orca/LlongOrca-7B-16k
279,https://huggingface.co/OpenAssistant/llama2-70b-oasst-sft-v10
280,https://huggingface.co/RWKV/rwkv-4-14b-pile
281,https://huggingface.co/RWKV/rwkv-4-world-7b
282,https://huggingface.co/RWKV/rwkv-5-world-3b
283,https://huggingface.co/SciPhi/SciPhi-Mistral-7B-32k
284,https://huggingface.co/VAGOsolutions/SauerkrautLM-7b-HerO
285,https://huggingface.co/Xwin-LM/Xwin-LM-70B-V0.1
286,https://huggingface.co/amazon/FalconLite2
287,https://huggingface.co/blog/Pclanglais/common-corpus
288,https://huggingface.co/blog/community-datasets
289,https://huggingface.co/blog/idefics
290,https://huggingface.co/blog/idefics2
291,https://huggingface.co/cognitivecomputations/WizardLM-30B-Uncensored
292,https://huggingface.co/datasets/BAAI/JudgeLM-100K
293,https://huggingface.co/datasets/Open-Orca/OpenOrca
294,https://huggingface.co/datasets/cerebras/SlimPajama-627B
295,https://huggingface.co/deepnight-research/saily_100b
296,https://huggingface.co/kotoba-tech/kotoba-speech-v0.1
297,https://huggingface.co/moreh/MoMo-72B-lora-1.8.7-DPO
298,https://huggingface.co/spaces/facebook/MusicGen/tree/main
299,https://huggingface.co/stabilityai/stable-cascade
300,https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B
301,https://huggingface.co/vilm/vulture-180b
302,https://hyperwriteai.com/
303,https://imagen.research.google/
304,https://inceptioniai.org/jais/docs/Technicalpaper.pdf
305,https://inflection.ai/inflection-1
306,https://inflection.ai/inflection-2
307,https://inflection.ai/inflection-2-5
308,https://inflection.ai/press
309,https://junilearning.com/
310,https://keg.cs.tsinghua.edu.cn/glm-130b/
311,https://labs.perplexity.ai/
312,https://laion.ai/blog/laion-400-open-dataset/
313,https://laion.ai/blog/laion-5b/
314,https://laion.ai/blog/oig-dataset/
315,https://laion.ai/blog/open-flamingo/
316,https://llama.meta.com/llama3/
317,https://lmsys.org/blog/2023-03-30-vicuna/
318,https://m-bain.github.io/webvid-dataset/
319,https://machinelearning.apple.com/research/openelm
320,https://medium.com/yandex/yandex-publishes-yalm-100b-its-the-largest-gpt-like-neural-network-in-open-source-d1df53d0e9a6
321,https://mistral.ai/news/announcing-mistral-7b/
322,https://mistral.ai/news/codestral/
323,https://mistral.ai/news/le-chat-mistral/
324,https://mistral.ai/news/mistral-large/
325,https://neeva.com/blog/introducing-neevaai
326,https://neeva.com/index
327,https://news.agpt.co/
328,https://newsroom.spotify.com/2023-02-22/spotify-debuts-a-new-ai-dj-right-in-your-pocket/
329,https://openai.com/api/
330,https://openai.com/blog/chatgpt
331,https://openai.com/blog/introducing-chatgpt-and-whisper-apis
332,https://openai.com/blog/new-and-improved-content-moderation-tooling
333,https://openai.com/dall-e-3
334,https://openai.com/enterprise
335,https://openai.com/index/hello-gpt-4o/
336,https://openai.com/product/gpt-4
337,https://openai.com/sora
338,https://openreview.net/forum?id=UoEw6KigkUn
339,https://openreview.net/pdf?id=vOEXS39nOF
340,https://parti.research.google/
341,https://platform.openai.com/docs/model-index-for-researchers
342,https://platform.openai.com/docs/models/gpt-3-5
343,https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo
344,https://play.aidungeon.io
345,https://portkey.ai/
346,https://powerplatform.microsoft.com/en-us/
347,https://proceedings.neurips.cc/paper/2011/file/5dd9db5e033da9c6fb5ba83c7a7ebea9-Paper.pdf
348,https://proceedings.neurips.cc/paper_files/paper/2019/file/c20bb2d9a50d5ac1f713f8b34d9aac5a-Paper.pdf
349,https://quorablog.quora.com/Poe-1
350,https://qwenlm.github.io/blog/qwen-moe/
351,https://qwenlm.github.io/blog/qwen1.5/
352,https://re.express/index.html
353,https://reka.ai/reka-flash-an-efficient-and-capable-multimodal-language-model/
354,https://research.facebook.com/publications/voicebox-text-guided-multilingual-universal-speech-generation-at-scale/
355,https://robotics-transformer-x.github.io/
356,https://sambanova.ai/blog/samba-1-composition-of-experts-mode
357,https://sambanova.ai/blog/sambalingo-open-source-language-experts
358,https://sites.google.com/view/genie-2024
359,https://spreadprivacy.com/duckassist-launch/
360,https://stability-ai.squarespace.com/news/stable-audio-2-0
361,https://stability.ai/blog/deepfloyd-if-text-to-image-model
362,https://stability.ai/blog/stable-diffusion-public-release
363,https://stability.ai/news/introducing-stable-lm-2
364,https://stability.ai/news/introducing-stable-video-3d
365,https://stability.ai/stablediffusion
366,https://starling.cs.berkeley.edu/
367,https://static1.squarespace.com/static/6213c340453c3f502425776e/t/655ce779b9d47d342a93c890/1700587395994/stable_video_diffusion.pdf
368,https://storage.googleapis.com/deepmind-media/Teaching%20language%20models%20to%20support%20answers%20with%20verified%20quotes/Teaching%20language%20models%20to%20support%20answers%20with%20verified%20quotes.pdf
369,https://studio.ai21.com/playground/
370,https://support.microsoft.com/en-us/office/see-file-insights-before-you-open-a-file-87a23bbc-a516-42e2-a7b6-0ecb8259e026
371,https://support.microsoft.com/en-us/office/use-suggested-replies-in-outlook-19316194-0434-43ba-a742-6b5890157379
372,https://time-series-foundation-models.github.io/lag-llama.pdf
373,"https://time.com/6247678/openai-chatgpt-kenya-workers/#:~:text=In%20a%20statement%2C%20an%20OpenAI,datasets%20of%20tools%20like%20ChatGPT."
374,https://together.ai/blog/llama-2-7b-32k-instruct
375,https://together.ai/blog/redpajama-data-v2
376,https://twitter.com/Aleph__Alpha/status/1514576711492542477
377,https://twitter.com/lvwerra/status/1467933794699259908
378,https://txt.cohere.ai/multilingual/
379,https://txt.cohere.com/command-r/
380,https://txt.cohere.com/introducing-embed-v3/
381,https://uploads-ssl.webflow.com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_tech_paper.pdf
382,https://valle-demo.github.io/
383,https://vimalabs.github.io/
384,https://workspace.google.com/marketplace/app/claude_for_sheets/909417792257
385,https://www.adept.ai/blog/act-1
386,https://www.adept.ai/blog/adept-fuyu-heavy
387,https://www.adept.ai/blog/fuyu-8b
388,https://www.adept.ai/blog/persimmon-8b
389,https://www.ai21.com/blog/announcing-jamba
390,https://www.aleph-alpha.com/
391,https://www.anthropic.com/index/claude-2
392,https://www.anthropic.com/index/claude-2-1
393,https://www.anthropic.com/index/introducing-claude
394,https://www.anthropic.com/news/claude-3-family
395,https://www.askviable.com/
396,https://www.assemblyai.com/
397,https://www.assemblyai.com/blog/conformer-1/
398,https://www.bain.com/vector-digital/partnerships-alliance-ecosystem/openai-alliance/
399,https://www.bemyeyes.com/blog/introducing-be-my-eyes-virtual-volunteer
400,https://www.biorxiv.org/content/10.1101/2022.07.20.500902v2.full.pdf+html
401,https://www.biorxiv.org/content/10.1101/2022.10.10.511571v1
402,https://www.biorxiv.org/content/10.1101/2022.11.20.517210v2
403,https://www.cerebras.net/blog/btlm-3b-8k-7b-performance-in-a-3-billion-parameter-model/
404,https://www.cerebras.net/blog/cerebras-gpt-a-family-of-open-compute-efficient-large-language-models/
405,https://www.cognition-labs.com/introducing-devin
406,https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html
407,https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm
408,https://www.deepmind.com/blog/a-generalist-agent
409,https://www.docugami.com/generative-ai
410,https://www.ibm.com/blog/building-ai-for-business-ibms-granite-foundation-models/
411,https://www.ibm.com/products/watsonx-ai
412,https://www.khanacademy.org/khan-labs#khanmigo
413,https://www.lgresearch.ai/exaone
414,https://www.linkedin.com/
415,https://www.llm360.ai/
416,https://www.llm360.ai/paper2.pdf
417,https://www.microsoft.com/en-us/microsoft-365/excel
418,https://www.microsoft.com/en-us/microsoft-365/outlook/email-and-calendar-software-microsoft-outlook
419,https://www.microsoft.com/en-us/microsoft-365/powerpoint
420,https://www.microsoft.com/en-us/microsoft-365/word
421,https://www.microsoft.com/en-us/microsoft-teams/group-chat-software
422,https://www.microsoft.com/en-us/research/blog/efficiently-and-effectively-scaling-up-language-model-pretraining-for-best-language-representation-model-on-glue-and-superglue/?OCID=msr_blog_TNLRV5_tw
423,https://www.microsoft.com/en-us/research/blog/microsoft-turing-universal-language-representation-model-t-ulrv5-tops-xtreme-leaderboard-and-trains-100x-faster/
424,https://www.moonhub.ai/
425,https://www.mosaicml.com/blog/mpt-7b
426,https://www.nature.com/articles/s41586-021-03819-2
427,https://www.nature.com/articles/s41586-024-07441-w
428,https://www.nolano.org/services/Cformers/
429,https://www.notion.so/help/guides/notion-ai-for-docs
430,https://www.perplexity.ai/
431,https://www.perplexity.ai/sql
432,https://www.prnewswire.com/news-releases/baidu-launches-ernie-4-0-foundation-model-leading-a-new-wave-of-ai-native-applications-301958681.html
433,https://www.reka.ai/news/reka-core-our-frontier-class-multimodal-language-model
434,https://www.robinai.co.uk/
435,https://www.salesforce.com/news/stories/chatgpt-app-for-slack/
436,https://www.salesforce.com/products/einstein/overview/?d=cta-body-promo-8
437,https://www.sanalabs.com/
438,https://www.servicenow.com/company/media/press-room/huggingface-nvidia-launch-starcoder2.html
439,https://www.sktelecom.com/en/press/press_detail.do?idx=1582
440,https://www.thetrevorproject.org/
441,https://www.together.ai/blog/stripedhyena-7b
442,https://www.together.xyz/blog/openchatkit
443,https://www.together.xyz/blog/redpajama
444,https://www.together.xyz/blog/releasing-v1-of-gpt-jt-powered-by-open-source-ai
445,https://www.transformify.ai/automate
446,https://www.tsinghua.edu.cn/en/info/1420/10473.htm
447,https://www.twelvelabs.io/blog/introducing-marengo-2-6
448,https://www.withnucleus.ai/
449,https://www.wordtune.com/
450,https://www.wordtune.com/read
451,https://www.youtube.com/
452,https://www.zjukg.org/project/OceanGPT/
453,https://x.ai/blog/grok-1.5v
454,https://you.com/
455,unknown
