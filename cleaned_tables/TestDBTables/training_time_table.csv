training_time_id,training_time
1,1 day
2,1 week
3,10 days
4,"10,000 steps in 7 hours"
5,100-1000 petaflop/s-days
6,1000 epochs
7,11 days
8,13 days
9,130.4 days
10,"14,284 GPU hours"
11,"145,152 hours (cumulative)"
12,15 days
13,15 days on 1536 TPUs
14,18 days according to [[the paper]](https://arxiv.org/abs/2210.15257)
15,2 days
16,2 million steps
17,2 months
18,2 weeks
19,2.5 to 5 days
20,"20,000 steps"
21,"24 days, according to [[the paper]](https://arxiv.org/pdf/2204.05999.pdf)"
22,"24,602 A100 GPU hours"
23,27 hours
24,29600 petaflop/s-days
25,3 days
26,3 months
27,30 minutes
28,3000 A100 hours
29,"320,256 GPU hours"
30,35 days
31,3640 petaflop/s-days
32,37 hours
33,38k GPU hours
34,39 days
35,4 days
36,4 days on a 16x16 TPU v3 slice
37,4 weeks
38,400K GPU hours
39,4096 A100 days
40,4108.80 petaflop/s-day
41,47.10 petaflop/s-day
42,47k A100 hours
43,48 days
44,5 hours
45,"50,000 GPU hours"
46,53 days
47,54 hours
48,6 hours
49,6 weeks
50,6.79 days
51,60 petaflops/s-days
52,60k training steps per day
53,63 hours on p4d.24xlarge EC2 instance
54,68 hours
55,7 days
56,70 hours on 3 epochs
57,7039 petaflop/s-days
58,71.12 petaflop/s-day
59,7303.24 petaflop/s-day
60,"750,000 iterations"
61,8 days
62,80 hours
63,84 days
64,9 months
65,9.5 days
66,92k GPU hours
67,"97,120 hours (cumulative)"
68,"Approximately 15 days, totaling over 350 GPU hours."
69,Less than 1 V100-hour
70,Less than two weeks
71,Several months
72,Unknown
73,few months
74,less than 9 days
75,less than 9 hours
76,unknown
